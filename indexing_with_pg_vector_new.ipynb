{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import psycopg2\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load PDF and Split Text\n",
    "loader = PyPDFLoader(\"Atomic habits.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(\"PDF loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split successfully!\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "texts = []\n",
    "for page in pages:\n",
    "    # Clean text and split into chunks\n",
    "    cleaned_content = page.page_content.replace('\\t', ' ').replace('\\n', ' ').strip().lower()\n",
    "    page_chunks = text_splitter.create_documents([cleaned_content])\n",
    "    texts.extend(page_chunks)\n",
    "\n",
    "print(\"Text split successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHANOOR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "HuggingFaceInstructEmbeddings loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHANOOR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\SHANOOR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "# Load HuggingFace Embeddings\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name=\"hkunlp/instructor-xl\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "print(\"HuggingFaceInstructEmbeddings loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Embeddings to File\n",
    "# # NOTE: Embeddings are saved to a file for testing purposes\n",
    "# # This step is used to validate whether embeddings generation is working correctly and for later use.\n",
    "# output_dir = 'embeddings_output'\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "# embeddings_file = os.path.join(output_dir, 'embeddings.txt')\n",
    "\n",
    "# with open(embeddings_file, 'w') as file:\n",
    "#     for idx, text_chunk in enumerate(texts):\n",
    "#         embedding = instructor_embeddings.embed_documents([text_chunk.page_content])[0]\n",
    "#         embedding_data = {\n",
    "#             \"id - \": idx + 1,\n",
    "#             \"text - \": text_chunk.page_content,\n",
    "#             \"embedding - \": embedding \n",
    "#         }\n",
    "#         file.write(json.dumps(embedding_data) + '\\n')\n",
    "\n",
    "# print(f\"Embeddings saved successfully in {embeddings_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL and Create Tables\n",
    "# NOTE: If PGVector installation issues persist, store embeddings directly in PostgreSQL using JSON format.\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"Sample_DataBase\",  \n",
    "    user=\"postgres\",           \n",
    "    password=\"root\",  \n",
    "    host=\"localhost\",          \n",
    "    port=\"5432\"                \n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Created table for JSON storage\n",
    "# create_table_query = \"\"\"\n",
    "# CREATE TABLE IF NOT EXISTS embeddings (\n",
    "#     id SERIAL PRIMARY KEY,\n",
    "#     text TEXT NOT NULL,\n",
    "#     embedding JSONB NOT NULL\n",
    "# );\n",
    "# \"\"\"\n",
    "# cursor.execute(create_table_query)\n",
    "# conn.commit()\n",
    "\n",
    "# # Insert Embeddings into PostgreSQL (Manually Insertion)\n",
    "# with open(embeddings_file, 'r') as file:\n",
    "#     for line in file:\n",
    "#         embedding_data = json.loads(line)\n",
    "#         text = embedding_data[\"text - \"]\n",
    "#         embedding = embedding_data[\"embedding - \"]\n",
    "        \n",
    "#         insert_query = \"\"\"\n",
    "#         INSERT INTO embeddings (text, embedding)\n",
    "#         VALUES (%s, %s);\n",
    "#         \"\"\"\n",
    "#         cursor.execute(insert_query, (text, json.dumps(embedding)))\n",
    "#         conn.commit()\n",
    "\n",
    "# print(\"Embeddings inserted into PostgreSQL successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table for PGVector\n",
    "# NOTE: The PGVector table is used for vector-based storage.\n",
    "create_table_query_for_pgvector = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS embeddings_using_pgvector (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    text TEXT NOT NULL,\n",
    "    embedding vector(768)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query_for_pgvector)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # User-Defined Document Class\n",
    "# # NOTE: Created to handle embedding data for PGVector, as it requires specific document structures.\n",
    "# # instead creating embeddings from start instead i used stored embed so for that i create document class\n",
    "# class Document:\n",
    "#     def __init__(self, text, embedding):\n",
    "#         self.page_content = text\n",
    "#         self.metadata = {\"embedding\": embedding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Embeddings from File and Create PGVector Documents\n",
    "# docs = []\n",
    "# a = 1\n",
    "# with open(embeddings_file, 'r') as file:\n",
    "#     for line in file:\n",
    "#         embedding_data = json.loads(line)\n",
    "#         text = embedding_data[\"text - \"]\n",
    "#         embedding = embedding_data[\"embedding - \"]\n",
    "#         docs.append(Document(text, embedding)) \n",
    "#         print(f\"No - {a}\")\n",
    "#         a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PGVector\n",
    "COLLECTION_NAME = \"Atomic Habits PDF\"\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=\"psycopg2\",\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    database=\"Sample_DataBase\",\n",
    "    user=\"postgres\",\n",
    "    password=\"root\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PGVector Store\n",
    "# NOTE: PGVector requires the documents list and embeddings to be set up properly.\n",
    "db = PGVector.from_documents(\n",
    "    embedding=instructor_embeddings,\n",
    "    documents=texts,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True\n",
    ")\n",
    "# pause in between takes to much time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PGVector for Querying\n",
    "pgvector_docsearch = PGVector(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=instructor_embeddings,\n",
    ")\n",
    "\n",
    "def run_query_pgvector(docsearch, query, top_k=4):\n",
    "    docs = docsearch.similarity_search(query, k=top_k)\n",
    "    results = [doc.page_content for doc in docs]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Query on PGVector\n",
    "query = \"How to build better habits?\"\n",
    "results = run_query_pgvector(pgvector_docsearch, query)\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"Result {i}: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch Data from PostgreSQL by ID\n",
    "# user_input_id = input(\"Enter the ID of the embedding you want to fetch: \")\n",
    "\n",
    "# fetch_query = \"SELECT text, embedding FROM embeddings WHERE id = %s;\"\n",
    "# cursor.execute(fetch_query, (user_input_id,))\n",
    "\n",
    "# result = cursor.fetchone()\n",
    "\n",
    "# if result:\n",
    "#     text, embedding = result\n",
    "#     print(f\"Text: {text}\")\n",
    "#     print(f\"Embedding: {embedding}\")\n",
    "# else:\n",
    "#     print(f\"No data found for ID {user_input_id}\")\n",
    "\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "# print(\"Cursor successfully closed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
